{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import keras\n",
    "import sys\n",
    "import io\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Mushrooms.txt', 'r') as mushies:\n",
    "    mushroom_accounts = mushies.read()\n",
    "\n",
    "with open('data/Cannabis.txt', 'r') as pot:\n",
    "    cannabis_accounts = pot.read()\n",
    "    \n",
    "with open('data/MDMA.txt', 'r') as molly:\n",
    "    mdma_accounts = molly.read()\n",
    "    \n",
    "with open('data/LSD.txt', 'r') as acid:\n",
    "    lsd_accounts = acid.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a model trained on whatever text it is given. \n",
    "def make_model(text):\n",
    "    chars = sorted(list(set(text)))\n",
    "    char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "    indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "    seqlen = 40\n",
    "    step = seqlen\n",
    "    sentences = []\n",
    "    for i in range(0, len(text) - seqlen - 1, step):\n",
    "        sentences.append(text[i: i + seqlen + 1])\n",
    "\n",
    "    x = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, (char_in, char_out) in enumerate(zip(sentence[:-1], sentence[1:])):\n",
    "            x[i, t, char_indices[char_in]] = 1\n",
    "            y[i, t, char_indices[char_out]] = 1\n",
    "\n",
    "\n",
    "    logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "    model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=RMSprop(learning_rate=0.1),\n",
    "        metrics=['categorical_crossentropy', 'accuracy']\n",
    "    )\n",
    "\n",
    "\n",
    "    def sample(preds, temperature=1.0):\n",
    "        \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = np.exp(np.log(preds) / temperature)  # softmax\n",
    "        preds = preds / np.sum(preds)                #\n",
    "        probas = np.random.multinomial(1, preds, 1)  # sample index\n",
    "        return np.argmax(probas)                     #\n",
    "\n",
    "\n",
    "    def on_epoch_end(epoch, _):\n",
    "        \"\"\"Function invoked at end of each epoch. Prints generated text.\"\"\"\n",
    "        print()\n",
    "        print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "        start_index = random.randint(0, len(text) - seqlen - 1)\n",
    "\n",
    "        diversity = 0.5\n",
    "        \n",
    "        print('----- diversity:', diversity)\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + seqlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1\n",
    "            preds = model.predict(x_pred, verbose=0)\n",
    "            next_index = sample(preds[0, -1], diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            sentence = sentence[1:] + next_char\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "    print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=4,\n",
    "              callbacks=[print_callback])\n",
    "\n",
    "    #%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/4\n",
      "124905/124905 [==============================] - 136s 1ms/step - loss: 2.0591 - categorical_crossentropy: 2.0591 - accuracy: 0.4770\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"tterns behind my eyes. YES! It wasn't a \"\n",
      "tterns behind my eyes. YES! It wasn't a sile and end about the trees with the sections and we were sit my coming of my experience the trip. The begin to the tri"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:40: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p. The coming at the mushrooms were and were be weird and a started and a screat and here and and this world with my mind before there were come out of the change of the trip. All but everyone where the bad my friends.  The world to the communicating as projection, I was trip. I \n",
      "Epoch 2/4\n",
      "124905/124905 [==============================] - 142s 1ms/step - loss: 1.5044 - categorical_crossentropy: 1.5044 - accuracy: 0.5569\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" ride.\n",
      "\n",
      "T+3:30: At this point, my nausea\"\n",
      " ride.\n",
      "\n",
      "T+3:30: At this point, my nausea all that we went to trip and the started and the entire as the tripping and the self and i decided I thought I see the trip to the car when I had to see shrooms and the ein to we first of the heard and the couple and the next didnÂ’t walked at the time to be experience. The so down to take and should had to the trip with the part of about the great. I said down into the energy and the trip, find o\n",
      "Epoch 3/4\n",
      "124905/124905 [==============================] - 143s 1ms/step - loss: 1.4794 - categorical_crossentropy: 1.4794 - accuracy: 0.5629\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"They were speaking some language that I'\"\n",
      "They were speaking some language that I've a lot of seemed to never walk a most time and started to say the way that I look and help of the time as I began to tell the feel of the started with me a friend I was a side and all to take of the part of the friends of the bed after over to be when we were going to watching at the painted me interested to be of heavy and the walls were probably a tood the experience I was not the ride and was\n",
      "Epoch 4/4\n",
      "124905/124905 [==============================] - 150s 1ms/step - loss: 1.4572 - categorical_crossentropy: 1.4572 - accuracy: 0.5681\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"y sketched that they were not going to w\"\n",
      "y sketched that they were not going to what I was seen and then was for the shrooms saw the trip.  I think I was a realised the trip, but they were the most of my room they were let the started to the part of the house who the park. There was the light to the matterns on my friends tried to get while the grants some life I looked at the sense and a free saw a lot the streams and control the faces from the water the scream to realized th\n"
     ]
    }
   ],
   "source": [
    "mushrooms = make_model(mushroom_accounts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
