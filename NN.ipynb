{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import keras\n",
    "import sys\n",
    "import io\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Mushrooms.txt', 'r') as mushies:\n",
    "    mushroom_accounts = mushies.read()\n",
    "\n",
    "with open('data/Cannabis.txt', 'r') as pot:\n",
    "    cannabis_accounts = pot.read()\n",
    "    \n",
    "with open('data/MDMA.txt', 'r') as molly:\n",
    "    mdma_accounts = molly.read()\n",
    "    \n",
    "with open('data/LSD.txt', 'r') as acid:\n",
    "    lsd_accounts = acid.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_text(text):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a model trained on whatever text it is given. \n",
    "def make_model(text):\n",
    "    chars = sorted(list(set(text)))\n",
    "    char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "    indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "    seqlen = 40\n",
    "    step = seqlen\n",
    "    sentences = []\n",
    "    for i in range(0, len(text) - seqlen - 1, step):\n",
    "        sentences.append(text[i: i + seqlen + 1])\n",
    "\n",
    "    x = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, (char_in, char_out) in enumerate(zip(sentence[:-1], sentence[1:])):\n",
    "            x[i, t, char_indices[char_in]] = 1\n",
    "            y[i, t, char_indices[char_out]] = 1\n",
    "\n",
    "\n",
    "    logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "    model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=RMSprop(learning_rate=0.1),\n",
    "        metrics=['categorical_crossentropy', 'accuracy']\n",
    "    )\n",
    "\n",
    "\n",
    "    def sample(preds, temperature=1.0):\n",
    "        \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = np.exp(np.log(preds) / temperature)  # softmax\n",
    "        preds = preds / np.sum(preds)                #\n",
    "        probas = np.random.multinomial(1, preds, 1)  # sample index\n",
    "        return np.argmax(probas)                     #\n",
    "\n",
    "\n",
    "    def on_epoch_end(epoch, _):\n",
    "        \"\"\"Function invoked at end of each epoch. Prints generated text.\"\"\"\n",
    "        print()\n",
    "        print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "        start_index = random.randint(0, len(text) - seqlen - 1)\n",
    "\n",
    "        diversity = 0.5\n",
    "        \n",
    "        print('----- diversity:', diversity)\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + seqlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1\n",
    "            preds = model.predict(x_pred, verbose=0)\n",
    "            next_index = sample(preds[0, -1], diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            sentence = sentence[1:] + next_char\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "    print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=10,\n",
    "              callbacks=[print_callback])\n",
    "    \n",
    "    return model\n",
    "\n",
    "    #%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "62452/62452 [==============================] - 74s 1ms/step - loss: 2.0112 - categorical_crossentropy: 2.0112 - accuracy: 0.4705\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e.  I decide I would be more comfortable\"\n",
      "e.  I decide I would be more comfortable of them, and the manding black to said, the time at a to didn't trip. I started she thought the time, and of the told a half to didn't can the and dont coming and not that was the fact the difficult for the experience of the took and and a so stating the trip and made into the first shifting of what at the trip, that I was colds. I felt a choid ground to my mind of the part and and the more of t\n",
      "Epoch 2/10\n",
      "62452/62452 [==============================] - 72s 1ms/step - loss: 1.4922 - categorical_crossentropy: 1.4922 - accuracy: 0.5558\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"4, 2000Views: 91,879\n",
      "[ View as PDF (for \"\n",
      "4, 2000Views: 91,879\n",
      "[ View as PDF (for p Contances.  I was a to be when I saw me was somehow that I was and the such a few many and was in the strong well and looking that we were the time and mushrooms I started a powerful was som"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:40: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e started to some be the mean and the deal it was all a smoked and come on the both was the surface of when the perfect the ground them that we had to little to be a mushrooms to secomed to be the perfect me\n",
      "Epoch 3/10\n",
      "62452/62452 [==============================] - 70s 1ms/step - loss: 1.4667 - categorical_crossentropy: 1.4667 - accuracy: 0.5630\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" decided to cook them all up into one bi\"\n",
      " decided to cook them all up into one bit of my friends and where I started to take the sitter fresh in the full the friends and the physical creations we were the started to not the trip I can further the world a trip when I didn't be the flactions and mushrooms that I can the trees the beautiful stop took me to trip. It was a been the heart that I was being shrooms the straight many experience the straight the appreasure and the trip \n",
      "Epoch 4/10\n",
      "62452/62452 [==============================] - 69s 1ms/step - loss: 1.4584 - categorical_crossentropy: 1.4584 - accuracy: 0.5654\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"areness, to switch it off. Vision was mi\"\n",
      "areness, to switch it off. Vision was minutes with the first of my body was a little because I was a diving known and show must the more that I had to be ate a with the group and with a blue hold and and many discover in my grapsing and think at this way to close and then I could felt how was tripped and on my morning to colors of the trip to be me and think this something that I was the light and a friends of about to make the particul\n",
      "Epoch 5/10\n",
      "62452/62452 [==============================] - 74s 1ms/step - loss: 1.4488 - categorical_crossentropy: 1.4488 - accuracy: 0.5685\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"uess though, I wrote this just to warn p\"\n",
      "uess though, I wrote this just to warn proving of the really that I was like a house that I was a strange and the bed there was not in the straight better of the first wise with like mushrooms in the body-poster and the house that he was not a few pursus to come off the mushrooms. I don't was a completely and watching the sense of my trip on my bed and still the moment of the even to watch the most things were we were all are a few so e\n",
      "Epoch 6/10\n",
      "62452/62452 [==============================] - 77s 1ms/step - loss: 1.4419 - categorical_crossentropy: 1.4419 - accuracy: 0.5702\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ay I have no idea how that happened. I w\"\n",
      "ay I have no idea how that happened. I was notice to the starting to me as if I am we were invisible to the perception that it was supposition of when I was the head. The point I sat to the room to me dayed sure it was had in the trip continued to my mind and I do could have a light was standing being things of the things in a moment at my sense and speak at the sky of the sense and it was still experienced the seriously with the starin\n",
      "Epoch 7/10\n",
      "62452/62452 [==============================] - 71s 1ms/step - loss: 1.4559 - categorical_crossentropy: 1.4559 - accuracy: 0.5678\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"g a bright green shirt. As we walk aroun\"\n",
      "g a bright green shirt. As we walk arounded the time I sat and brother and we had to see the most trip completely started to sounded to the drught a mental beautiful and I was still the serient that a completely the sound there, but I was theme patterns into the experience, I was go on the time everything and my place and we were going to have dose into the mushrooms for me and the day and and the experiences mother.  I was not intense \n",
      "Epoch 8/10\n",
      "62452/62452 [==============================] - 72s 1ms/step - loss: 1.4541 - categorical_crossentropy: 1.4541 - accuracy: 0.5688\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" Every time I looked up, there was nothi\"\n",
      " Every time I looked up, there was nothing his beautiful what the completely the most and I had a trip on the bodies with the power still managed and the outside of the thinking in the something and the completely a stood the watching and they were a more the sounds of the hours of the first of the more party mean that I was streeted my bed. I was a first time he said were and be in the bares. I was such alone of my first find a more th\n",
      "Epoch 9/10\n",
      "62452/62452 [==============================] - 73s 1ms/step - loss: 1.4378 - categorical_crossentropy: 1.4378 - accuracy: 0.5724\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"d the song playing now was called Eyes \"\n",
      "d the song playing now was called Eyes of the some time something the trip and on the same find was the completely a completely and are a warm and was a looking in the bed to say to see this is the serious seemed to go and something in the park in the same showed around and the trip that my eyes for the beauty of the sounds to me found out coal and completely as I saw to a comparts and the as I take me said I was a little car to sleep \n",
      "Epoch 10/10\n",
      "62452/62452 [==============================] - 78s 1ms/step - loss: 1.4376 - categorical_crossentropy: 1.4376 - accuracy: 0.5720\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"s who weren't tripping but said it was o\"\n",
      "s who weren't tripping but said it was only a back at the same time of the faces and the experiences as a sensationalight and my fest as the last wondranged the asking on the room. We were only as the such it was a portivation.  I started to continuo a verything an able to felt a few listening to explain a trip were not all my continuously any time a little living in a earlight and my trip I had the last and a car particulating me to an\n"
     ]
    }
   ],
   "source": [
    "mushrooms = make_model(mushroom_accounts[:len(mushroom_accounts)//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41149/41149 [==============================] - 48s 1ms/step - loss: 2.7969 - categorical_crossentropy: 2.7969 - accuracy: 0.3510\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"her girl at the way home and started tal\"\n",
      "her girl at the way home and started talking and I hours offer a as trying it was as to contess that the sleep and the friend that I was sense still that I didn't drug smoked my earlding that I was with a from and started and chatted that I have friends some that I have and and lays and and that I have come and I felt have come things the the does of the right and started this and the talking and and conting the called at there all that\n",
      "Epoch 2/10\n",
      "41149/41149 [==============================] - 47s 1ms/step - loss: 1.5614 - categorical_crossentropy: 1.5614 - accuracy: 0.5430\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" that I wouldn't tell to anybody (except\"\n",
      " that I wouldn't tell to anybody (except off the some purpound to the soon in one me that I had to go to danced that I was on the sitten that I couldn't stop to the stated and went on the music I wanted to started to trance before to think the soort that I had a lot to the continot E also someone and there took on the in the sat that I do me and for that the too the sat that I saw the rolled that I had some ofen off the care that I safe\n",
      "Epoch 3/10\n",
      "41149/41149 [==============================] - 49s 1ms/step - loss: 1.5003 - categorical_crossentropy: 1.5003 - accuracy: 0.5587\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ip... thats my primary motivation this t\"\n",
      "ip... thats my primary motivation this take to the first the restly and the energy to go to be just clowly real because I was really and and spenk and was so I had a face entery of the fact and the a green to the entiich and club so never wanted to the sensation of the experience: Not Given \n",
      "Publishy with to den beautiful and far I did it was person and on E the most of an in out with the energet the hands and I took a good other the pa\n",
      "Epoch 4/10\n",
      "41149/41149 [==============================] - 49s 1ms/step - loss: 1.4780 - categorical_crossentropy: 1.4780 - accuracy: 0.5640\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"tzung mit mir selbst war eine komplett a\"\n",
      "tzung mit mir selbst war eine komplett around to the most at the experienced some to the to in the took the first time I took the beauty and my mouth and to it was so the to be some to a most to the started to a stops, but and the and for a began to didn't was a soft myself amazing and in the simple to so them comparion and so colors to the started a more I was them be dance some to the to took my friend to stomar and MDMA and on the to\n",
      "Epoch 5/10\n",
      "41149/41149 [==============================] - 48s 1ms/step - loss: 1.4635 - categorical_crossentropy: 1.4635 - accuracy: 0.5689\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \", when other people are coming in for a \"\n",
      ", when other people are coming in for a good friends and the energy and connection and so the world the change and this time I am a completely was all so the beats and my friend and I felt love of completely that I "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:40: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "was very front the go to be go to my good by this probably the early so we walked many subses energy and explain is to really became time pill in a going on my friends in the experience to do in the body and was all good minu\n",
      "Epoch 6/10\n",
      "41149/41149 [==============================] - 51s 1ms/step - loss: 1.4632 - categorical_crossentropy: 1.4632 - accuracy: 0.5686\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e its size.  My phone felt like the God \"\n",
      "e its size.  My phone felt like the God and that the mind of and difficult coming to my and at this best my second in the coming to the feel my sitter the body.  I have a new seemed to the feel my eyes of a time on my eyes were the mind of the body.  I have been back to be begin in my body took the sension and I am in a club a book to the eyes.\n",
      "\n",
      "It had a time that I could have to do the high been be in the book in the body. I don't all \n",
      "Epoch 7/10\n",
      "41149/41149 [==============================] - 48s 1ms/step - loss: 1.4559 - categorical_crossentropy: 1.4559 - accuracy: 0.5705\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"l topics. \n",
      "\n",
      "By this time I really feel l\"\n",
      "l topics. \n",
      "\n",
      "By this time I really feel like that I was had to be a good time for the right after a little anything a world my mind and the back of down some all of a good this better of the part and something really a light a come minutes with a conting my relative an experience a stape in the effect of this person that this able to was a friend in a before, and we stopped a seconds and my water was able to low back to cannot a from a f\n",
      "Epoch 8/10\n",
      "41149/41149 [==============================] - 51s 1ms/step - loss: 1.4578 - categorical_crossentropy: 1.4578 - accuracy: 0.5703\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"that hes never heard of someone halluci\"\n",
      "that hes never heard of someone halluciness.  I was the experience: Not Giggest the since come to real being the speck obmer the trip experience: Not Giggest the part and because we being she was the best were very first time and there I lay in the more first time in the head and the head and there were strangers and there I would the different me around the straight but a minded and that I was not time of the pice of the bedroom of th\n",
      "Epoch 9/10\n",
      "41149/41149 [==============================] - 46s 1ms/step - loss: 1.4530 - categorical_crossentropy: 1.4530 - accuracy: 0.5719\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"nt out with them. It was about 30-45 min\"\n",
      "nt out with them. It was about 30-45 minutes.  The lights and that I was not taken a part to me and so our house and had got so see a controll. I was an eo had a taster and was got to the parting me at the definitely definitely decided to talk up and was feeling of my face. I was at the get on the stand, and the didn't get time and so he was so said for a meaned the good are so and had been time and so content and it was a started a way\n",
      "Epoch 10/10\n",
      "41149/41149 [==============================] - 48s 1ms/step - loss: 1.4450 - categorical_crossentropy: 1.4450 - accuracy: 0.5738\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"h MDMA. From NOW on, I will start with 1\"\n",
      "h MDMA. From NOW on, I will start with 10 hours when the most the same week at the content shakence and were the whole fact the day what I had a never was content and stay had a beautiful hitted to the sensations was a started a rave the same a best the next day and dance and would have the nature than which was some days and I do the pill had a for a party das that believed to the couple and the beauty and the hoss and was waking that \n"
     ]
    }
   ],
   "source": [
    "mdma = make_model(mdma_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
