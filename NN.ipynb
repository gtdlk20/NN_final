{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import keras\n",
    "import sys\n",
    "import io\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from datetime import datetime\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Mushrooms.txt', 'r') as mushies:\n",
    "    mushroom_accounts = mushies.read()\n",
    "\n",
    "with open('data/Cannabis.txt', 'r') as pot:\n",
    "    cannabis_accounts = pot.read()\n",
    "    \n",
    "with open('data/MDMA.txt', 'r') as molly:\n",
    "    mdma_accounts = molly.read()\n",
    "    \n",
    "with open('data/LSD.txt', 'r', encoding='utf-8') as acid:\n",
    "    lsd_accounts = acid.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "        \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = np.exp(np.log(preds) / temperature)  # softmax\n",
    "        preds = preds / np.sum(preds)                #\n",
    "        probas = np.random.multinomial(1, preds, 1)  # sample index\n",
    "        return np.argmax(probas)                     #\n",
    "\n",
    "\n",
    "#returns a model trained on whatever text it is given. \n",
    "def make_model(text):\n",
    "    chars = sorted(list(set(text)))\n",
    "    char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "    indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "    seqlen = 40\n",
    "    step = seqlen\n",
    "    sentences = []\n",
    "    for i in range(0, len(text) - seqlen - 1, step):\n",
    "        sentences.append(text[i: i + seqlen + 1])\n",
    "\n",
    "    x = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, (char_in, char_out) in enumerate(zip(sentence[:-1], sentence[1:])):\n",
    "            x[i, t, char_indices[char_in]] = 1\n",
    "            y[i, t, char_indices[char_out]] = 1\n",
    "\n",
    "\n",
    "    logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "    model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=RMSprop(learning_rate=0.1),\n",
    "        metrics=['categorical_crossentropy', 'accuracy']\n",
    "    )\n",
    "\n",
    "\n",
    "    def on_epoch_end(epoch, _):\n",
    "        \"\"\"Function invoked at end of each epoch. Prints generated text.\"\"\"\n",
    "        print()\n",
    "        print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "        start_index = random.randint(0, len(text) - seqlen - 1)\n",
    "\n",
    "        diversity = 0.5\n",
    "        \n",
    "        print('----- diversity:', diversity)\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + seqlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1\n",
    "            preds = model.predict(x_pred, verbose=0)\n",
    "            next_index = sample(preds[0, -1], diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            sentence = sentence[1:] + next_char\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "    print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=10,\n",
    "              callbacks=[print_callback])\n",
    "    \n",
    "    return model, x, y\n",
    "\n",
    "    #%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "62452/62452 [==============================] - 74s 1ms/step - loss: 2.0112 - categorical_crossentropy: 2.0112 - accuracy: 0.4705\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e.  I decide I would be more comfortable\"\n",
      "e.  I decide I would be more comfortable of them, and the manding black to said, the time at a to didn't trip. I started she thought the time, and of the told a half to didn't can the and dont coming and not that was the fact the difficult for the experience of the took and and a so stating the trip and made into the first shifting of what at the trip, that I was colds. I felt a choid ground to my mind of the part and and the more of t\n",
      "Epoch 2/10\n",
      "62452/62452 [==============================] - 72s 1ms/step - loss: 1.4922 - categorical_crossentropy: 1.4922 - accuracy: 0.5558\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"4, 2000Views: 91,879\n",
      "[ View as PDF (for \"\n",
      "4, 2000Views: 91,879\n",
      "[ View as PDF (for p Contances.  I was a to be when I saw me was somehow that I was and the such a few many and was in the strong well and looking that we were the time and mushrooms I started a powerful was som"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:40: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e started to some be the mean and the deal it was all a smoked and come on the both was the surface of when the perfect the ground them that we had to little to be a mushrooms to secomed to be the perfect me\n",
      "Epoch 3/10\n",
      "62452/62452 [==============================] - 70s 1ms/step - loss: 1.4667 - categorical_crossentropy: 1.4667 - accuracy: 0.5630\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" decided to cook them all up into one bi\"\n",
      " decided to cook them all up into one bit of my friends and where I started to take the sitter fresh in the full the friends and the physical creations we were the started to not the trip I can further the world a trip when I didn't be the flactions and mushrooms that I can the trees the beautiful stop took me to trip. It was a been the heart that I was being shrooms the straight many experience the straight the appreasure and the trip \n",
      "Epoch 4/10\n",
      "62452/62452 [==============================] - 69s 1ms/step - loss: 1.4584 - categorical_crossentropy: 1.4584 - accuracy: 0.5654\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"areness, to switch it off. Vision was mi\"\n",
      "areness, to switch it off. Vision was minutes with the first of my body was a little because I was a diving known and show must the more that I had to be ate a with the group and with a blue hold and and many discover in my grapsing and think at this way to close and then I could felt how was tripped and on my morning to colors of the trip to be me and think this something that I was the light and a friends of about to make the particul\n",
      "Epoch 5/10\n",
      "62452/62452 [==============================] - 74s 1ms/step - loss: 1.4488 - categorical_crossentropy: 1.4488 - accuracy: 0.5685\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"uess though, I wrote this just to warn p\"\n",
      "uess though, I wrote this just to warn proving of the really that I was like a house that I was a strange and the bed there was not in the straight better of the first wise with like mushrooms in the body-poster and the house that he was not a few pursus to come off the mushrooms. I don't was a completely and watching the sense of my trip on my bed and still the moment of the even to watch the most things were we were all are a few so e\n",
      "Epoch 6/10\n",
      "62452/62452 [==============================] - 77s 1ms/step - loss: 1.4419 - categorical_crossentropy: 1.4419 - accuracy: 0.5702\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ay I have no idea how that happened. I w\"\n",
      "ay I have no idea how that happened. I was notice to the starting to me as if I am we were invisible to the perception that it was supposition of when I was the head. The point I sat to the room to me dayed sure it was had in the trip continued to my mind and I do could have a light was standing being things of the things in a moment at my sense and speak at the sky of the sense and it was still experienced the seriously with the starin\n",
      "Epoch 7/10\n",
      "62452/62452 [==============================] - 71s 1ms/step - loss: 1.4559 - categorical_crossentropy: 1.4559 - accuracy: 0.5678\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"g a bright green shirt. As we walk aroun\"\n",
      "g a bright green shirt. As we walk arounded the time I sat and brother and we had to see the most trip completely started to sounded to the drught a mental beautiful and I was still the serient that a completely the sound there, but I was theme patterns into the experience, I was go on the time everything and my place and we were going to have dose into the mushrooms for me and the day and and the experiences mother.  I was not intense \n",
      "Epoch 8/10\n",
      "62452/62452 [==============================] - 72s 1ms/step - loss: 1.4541 - categorical_crossentropy: 1.4541 - accuracy: 0.5688\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" Every time I looked up, there was nothi\"\n",
      " Every time I looked up, there was nothing his beautiful what the completely the most and I had a trip on the bodies with the power still managed and the outside of the thinking in the something and the completely a stood the watching and they were a more the sounds of the hours of the first of the more party mean that I was streeted my bed. I was a first time he said were and be in the bares. I was such alone of my first find a more th\n",
      "Epoch 9/10\n",
      "62452/62452 [==============================] - 73s 1ms/step - loss: 1.4378 - categorical_crossentropy: 1.4378 - accuracy: 0.5724\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"d the song playing now was called Eyes \"\n",
      "d the song playing now was called Eyes of the some time something the trip and on the same find was the completely a completely and are a warm and was a looking in the bed to say to see this is the serious seemed to go and something in the park in the same showed around and the trip that my eyes for the beauty of the sounds to me found out coal and completely as I saw to a comparts and the as I take me said I was a little car to sleep \n",
      "Epoch 10/10\n",
      "62452/62452 [==============================] - 78s 1ms/step - loss: 1.4376 - categorical_crossentropy: 1.4376 - accuracy: 0.5720\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"s who weren't tripping but said it was o\"\n",
      "s who weren't tripping but said it was only a back at the same time of the faces and the experiences as a sensationalight and my fest as the last wondranged the asking on the room. We were only as the such it was a portivation.  I started to continuo a verything an able to felt a few listening to explain a trip were not all my continuously any time a little living in a earlight and my trip I had the last and a car particulating me to an\n"
     ]
    }
   ],
   "source": [
    "mushrooms, mush_x, mush_y = make_model(mushroom_accounts[:len(mushroom_accounts)//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "41238/41238 [==============================] - 56s 1ms/step - loss: 4.2157 - categorical_crossentropy: 4.2157 - accuracy: 0.1512: 4s - loss: 4.3629 - categorical_crossentro\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"dancing again, and P's bowl shattered on\"\n",
      "dancing again, and P's bowl shattered on t nd wave we wind wa pt ind pre ind wat tnd tin we the tind win  t  w t an wan war wat wary tick rand the wo  d wict an wind th un to to t expering wing we  wand win wr ind go ts und wi w and wo we f an t nc  wat for ar wand wo p t+ and the ind the fe wang  I wing bon t five wo w and wo thor ind and s wing con d waro ware wang wo  cing wand wor ind d me wand walind nnd and wat wore winc win we ta\n",
      "Epoch 2/2\n",
      "41238/41238 [==============================] - 55s 1ms/step - loss: 1.7526 - categorical_crossentropy: 1.7526 - accuracy: 0.4935\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" as LaTeX (for geeks) ]\n",
      "[ Switch Colors \"\n",
      " as LaTeX (for geeks) ]\n",
      "[ Switch Colors ]\n",
      "\n",
      "MDMA (pill / tablet)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "BODY WEIGHT:\n",
      "125 able and the night in a past time in my body some in a person at the ward in a going to seen out and in a some most a fut me to me the the pill as a body in about\n",
      "\n",
      "\n",
      "\n",
      "I was a this my gime me to go to a suppost the car to puspeepus a mass his danned me all about\n",
      "\n",
      "\n",
      "\n",
      "I stare to me, a plange on and I dont the park so I could started to go to pla\n"
     ]
    }
   ],
   "source": [
    "mdma, mdma_x, mdma_y = make_model(mdma_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate trained model, to check saved and retreived model later\n",
    "def eval_model(model):\n",
    "    print(model.evaluate(mdma_x[-2000:], mdma_y[-2000:], verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trained_model(trained_model, drug_name):\n",
    "    now = datetime.now()\n",
    "    model_json = trained_model.to_json()\n",
    "    filename = drug_name + \"_\" + now.strftime(\"%m-%d_%H-%M-%S\")\n",
    "    with open(\"saved_models/\" + filename + \".json\", \"w+\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights\n",
    "    trained_model.save_weights(\"saved_models/\" + filename + \".h5\")\n",
    "    print(drug_name + \"_\" + now.strftime(\"%m-%d_%H-%M-%S\") + \" model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(filename):\n",
    "    # load model\n",
    "    json_file = open(\"saved_models/\" + filename + \".json\", \"r\")\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = keras.models.model_from_json(loaded_model_json)\n",
    "    # load weights\n",
    "    loaded_model.load_weights(\"saved_models/\" + filename + \".h5\")\n",
    "    print(filename + \" model loaded\")\n",
    "    # compile\n",
    "    loaded_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=RMSprop(learning_rate=0.1),\n",
    "        metrics=['categorical_crossentropy', 'accuracy']\n",
    "    )\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5087443685531616, 1.5087440013885498, 0.5576124787330627]\n",
      "mdma_11-30_16-23-01 model saved!\n"
     ]
    }
   ],
   "source": [
    "eval_model(mdma)\n",
    "save_trained_model(mdma, \"mdma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdma_11-30_16-23-01 model loaded\n",
      "[1.5087443685531616, 1.5087440013885498, 0.5576124787330627]\n"
     ]
    }
   ],
   "source": [
    "# hardcode filename here\n",
    "mdma_loaded = load_trained_model(\"mdma_11-30_16-23-01\")\n",
    "eval_model(mdma_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
