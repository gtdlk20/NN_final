{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import keras\n",
    "import sys\n",
    "import io\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from datetime import datetime\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Mushrooms.txt', 'r') as mushies:\n",
    "    mushroom_accounts = mushies.read()\n",
    "\n",
    "with open('data/Cannabis.txt', 'r') as pot:\n",
    "    cannabis_accounts = pot.read()\n",
    "    \n",
    "with open('data/MDMA.txt', 'r') as molly:\n",
    "    mdma_accounts = molly.read()\n",
    "    \n",
    "with open('data/LSD.txt', 'r', encoding='utf-8') as acid:\n",
    "    lsd_accounts = acid.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "        \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = np.exp(np.log(preds) / temperature)  # softmax\n",
    "        preds = preds / np.sum(preds)                #\n",
    "        probas = np.random.multinomial(1, preds, 1)  # sample index\n",
    "        return np.argmax(probas)                     #\n",
    "\n",
    "\n",
    "#returns a model trained on whatever text it is given. \n",
    "def make_model(text):\n",
    "    chars = sorted(list(set(text)))\n",
    "    char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "    indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "    seqlen = 40\n",
    "    step = seqlen\n",
    "    sentences = []\n",
    "    for i in range(0, len(text) - seqlen - 1, step):\n",
    "        sentences.append(text[i: i + seqlen + 1])\n",
    "\n",
    "    x = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, (char_in, char_out) in enumerate(zip(sentence[:-1], sentence[1:])):\n",
    "            x[i, t, char_indices[char_in]] = 1\n",
    "            y[i, t, char_indices[char_out]] = 1\n",
    "\n",
    "\n",
    "    logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "    model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=RMSprop(learning_rate=0.1),\n",
    "        metrics=['categorical_crossentropy', 'accuracy']\n",
    "    )\n",
    "\n",
    "\n",
    "    def on_epoch_end(epoch, _):\n",
    "        \"\"\"Function invoked at end of each epoch. Prints generated text.\"\"\"\n",
    "        print()\n",
    "        print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "        start_index = random.randint(0, len(text) - seqlen - 1)\n",
    "\n",
    "        diversity = 0.5\n",
    "        \n",
    "        print('----- diversity:', diversity)\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + seqlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1\n",
    "            preds = model.predict(x_pred, verbose=0)\n",
    "            next_index = sample(preds[0, -1], diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            sentence = sentence[1:] + next_char\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "    print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "    model.fit(x, y,\n",
    "        batch_size=128,\n",
    "        epochs=15,\n",
    "        callbacks=[print_callback])\n",
    "\n",
    "    return model, x, y\n",
    "\n",
    "    #%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "62585/62585 [==============================] - 113s 2ms/step - loss: 8.0134 - categorical_crossentropy: 8.0134 - accuracy: 0.1886\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"an a brief moment I felt wet and dirty. \"\n",
      "an a brief moment I felt wet and dirty.  I from look on crop to lo a to look on to look to on to look to to to look to look to lo to trip to look to to look the in look or look look or or tirl ot to on look to look look to look to for the look to look to to to look leat to plott to look to for on to to look to lo the look lig the look to to the frient to to look we re look the or look to to to to plont to to the to on look take to do lo\n",
      "Epoch 2/15\n",
      "62585/62585 [==============================] - 90s 1ms/step - loss: 1.7279 - categorical_crossentropy: 1.7279 - accuracy: 0.4973\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e two more 1.25g doses instead of just o\"\n",
      "e two more 1.25g doses instead of just on me on and I was a moning on my pould we wark a no the room with me understand wand on experience and can morth in my emotions and I was place and a looking like I was a recendoup because and we walked to be was play and had a waning wand was a because of spiritual was a because world becoming a colors and I was probably was so work and we want on a way my mind was a facine was in a could always \n",
      "Epoch 3/15\n",
      "62585/62585 [==============================] - 81s 1ms/step - loss: 1.5844 - categorical_crossentropy: 1.5844 - accuracy: 0.5332\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"a wallet washed up on the rocks.  This w\"\n",
      "a wallet washed up on the rocks.  This waters which in the way in an thought understand experience and a had in the play mind the reality to had stopped that I thought thought beautnent to the time the plathing how that ever thought and the half the something and the trip unfound that the hit it and the mushrooms look to for the personing the gram and the trip to do the wood is the trip to to do stomach through to the pottern of the cou\n",
      "Epoch 4/15\n",
      "62585/62585 [==============================] - 86s 1ms/step - loss: 1.5509 - categorical_crossentropy: 1.5510 - accuracy: 0.5423\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"allowed me to pass.\n",
      "\n",
      "The journey through\"\n",
      "allowed me to pass.\n",
      "\n",
      "The journey through the took my eyes the start to my ech see the seemed to mean with my mest conversape the way the head on me, and the heave and I have the beautiful while the means and I was a s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e_san_hjm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trange the can the watch get the beautiful the heart the story me and the hand the expected on the hard and the move the hands that was the way have seemed to come same the ground at the compected many the manter, the halls\n",
      "Epoch 5/15\n",
      "62585/62585 [==============================] - 85s 1ms/step - loss: 1.5399 - categorical_crossentropy: 1.5399 - accuracy: 0.5452\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"y ego. The present reality would fade, a\"\n",
      "y ego. The present reality would fade, and we mebic and and more me we were blue she was suddenly we were such eat the feeling of my buds of the whole the mushroom and we walked was the state the time the same was seemed he was when me me. \n",
      "\n",
      "After one with the stomach other was very sitting and which we were me the much of the time chosed stomach we were so we should dose completely my experience we were very such on my wonder world and\n",
      "Epoch 6/15\n",
      "62585/62585 [==============================] - 85s 1ms/step - loss: 1.5297 - categorical_crossentropy: 1.5297 - accuracy: 0.5480\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ry slowly rising.  I remember that once \"\n",
      "ry slowly rising.  I remember that once the the mental realized the sing the walls my hand how the thinking my heavy should had not a my experience and have a stop good the will with now and were good on the looked. I telling the way them the whole the with a the to my really consume the looking to week to look back and the took and I had not in the bathroom, the trip to know into the not discomforth that the thing mushrooms and the lon\n",
      "Epoch 7/15\n",
      "62585/62585 [==============================] - 83s 1ms/step - loss: 1.5220 - categorical_crossentropy: 1.5220 - accuracy: 0.5502\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"s. Coming to understandings about my own\"\n",
      "s. Coming to understandings about my own other the personner to strongers when I was something sure what were one the street respener mushrooms. Them became began to streer more the only images. I was all the partice to the started on the trip it was from the started to could remember the great that the started to let began to consists began to week to mete still the consist the super of the sure the trees, and was in my bed story to fe\n",
      "Epoch 8/15\n",
      "62585/62585 [==============================] - 88s 1ms/step - loss: 1.5330 - categorical_crossentropy: 1.5330 - accuracy: 0.5482\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"as possible. I came face to face with my\"\n",
      "as possible. I came face to face with my friends of the point you was messal to my shrooms from the put specing and a same of continued of scomet of my sitten and was meant a bit me. A part of the mountain more in the feeling and seat and of a more of good even and sound is a sounded in the strong in the body down and sound of moops of my body of with mind of an experience before of the last in and and was so me, and of completely was o\n",
      "Epoch 9/15\n",
      "62585/62585 [==============================] - 86s 1ms/step - loss: 1.5330 - categorical_crossentropy: 1.5330 - accuracy: 0.5478\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"in order to keep from burning out.  Let \"\n",
      "in order to keep from burning out.  Let never first I make a book and away of my moment and I was part of my friend and more and always care friend and which was from a dance before and my communies because of my human arrain and a compain and I was a grams of a grams the of my head to forget and discome in a bed of the mo faced and a beautiful a completely and of my brows and a make was a more and say was a good and seemed to me from a\n",
      "Epoch 10/15\n",
      "62585/62585 [==============================] - 91s 1ms/step - loss: 1.5311 - categorical_crossentropy: 1.5311 - accuracy: 0.5490\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" isn't it?! Look at those distorted, car\"\n",
      " isn't it?! Look at those distorted, car and walking on my house, so I began to be and extrean supposed to the door and that we were we were that I was were that we were something I was like the started in the more that was a past was begin to the same and with my hand to walk to it. I was beautiful this pastless on the most better and enjoy that was a face. I was the stronge with the started up a door and that was were a darkning to th\n",
      "Epoch 11/15\n",
      "62585/62585 [==============================] - 89s 1ms/step - loss: 1.5369 - categorical_crossentropy: 1.5369 - accuracy: 0.5476\n",
      "\n",
      "----- Generating text after Epoch: 10\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"these things that just happend to me did\"\n",
      "these things that just happend to me didnÂ’t suddenly and and of the most feeling for my follow feeling the quickly state and walk a consedd the started to the trip. I was and the true the man and a conscious water the later and happened to stop and amazing and had we were we werenÂ’t felt the down the didn't felt the one and wanted to happenly the thing and now this the played water the front of the part of the most to the to the most \n",
      "Epoch 12/15\n",
      "62585/62585 [==============================] - 83s 1ms/step - loss: 1.5370 - categorical_crossentropy: 1.5370 - accuracy: 0.5484\n",
      "\n",
      "----- Generating text after Epoch: 11\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"tes, sensitive face\n",
      "30 minutes; anxiousl\"\n",
      "tes, sensitive face\n",
      "30 minutes; anxiously to be the trip I had really come on a both that was the moving and a body conscious contelf the was the waith of the conceoul what I was a continue I thought a whole reality as I was a my friends we were to friend back and we back to pure the concering but that I was a finally in the water and a body was on a comfortably that I had to part of the months in the but from my body and in the fur tri\n",
      "Epoch 13/15\n",
      "62585/62585 [==============================] - 83s 1ms/step - loss: 1.5253 - categorical_crossentropy: 1.5253 - accuracy: 0.5507\n",
      "\n",
      "----- Generating text after Epoch: 12\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"s says in BE HERE NOW.  I hope next time\"\n",
      "s says in BE HERE NOW.  I hope next time part of a hang was that it was a beautiful that I was when he wanted to get that we was sitting to deep the point which it was about the most to drawn and when we wanted to states the way and I had the perfect it was a while on the coming what were was perfect things that we saw a people and I was the trug to the many find it and a seemed to be I was the started was tree and we were the shrooms t\n",
      "Epoch 14/15\n",
      "62585/62585 [==============================] - 83s 1ms/step - loss: 1.5250 - categorical_crossentropy: 1.5250 - accuracy: 0.5511\n",
      "\n",
      "----- Generating text after Epoch: 13\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"shing off dust and even singing to her (\"\n",
      "shing off dust and even singing to her (consis ]\n",
      "\n",
      "Mushrooms - P. gues (36), So\n",
      "os (1)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DÂ’ I was something and tripping the come mander conses, I couldn't everything to consumed down contempure I was a forest out was as the conseined the person, and weed started to week to started to week without the experienced, and the the some getting the of the trip was started and we were that I felt the couch conterper and all it was down s\n",
      "Epoch 15/15\n",
      "62585/62585 [==============================] - 89s 1ms/step - loss: 1.5315 - categorical_crossentropy: 1.5315 - accuracy: 0.5497\n",
      "\n",
      "----- Generating text after Epoch: 14\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ht as well humor P. On the way back T be\"\n",
      "ht as well humor P. On the way back T between and the in a sense of the took where the for our for a possage me and being and second some the trip is all for the mushrooms as realization time that she an extremely thoughts and and the up the gram of her to could to her because and the feeling in the mushrooms that the prepared being and she resine that I was because be this was street the trip a consical our reminder that where my prepa\n"
     ]
    }
   ],
   "source": [
    "mushrooms, mush_x, mush_y = make_model(mushroom_accounts[:len(mushroom_accounts)//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "41238/41238 [==============================] - 56s 1ms/step - loss: 4.2157 - categorical_crossentropy: 4.2157 - accuracy: 0.1512: 4s - loss: 4.3629 - categorical_crossentro\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"dancing again, and P's bowl shattered on\"\n",
      "dancing again, and P's bowl shattered on t nd wave we wind wa pt ind pre ind wat tnd tin we the tind win  t  w t an wan war wat wary tick rand the wo  d wict an wind th un to to t expering wing we  wand win wr ind go ts und wi w and wo we f an t nc  wat for ar wand wo p t+ and the ind the fe wang  I wing bon t five wo w and wo thor ind and s wing con d waro ware wang wo  cing wand wor ind d me wand walind nnd and wat wore winc win we ta\n",
      "Epoch 2/2\n",
      "41238/41238 [==============================] - 55s 1ms/step - loss: 1.7526 - categorical_crossentropy: 1.7526 - accuracy: 0.4935\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" as LaTeX (for geeks) ]\n",
      "[ Switch Colors \"\n",
      " as LaTeX (for geeks) ]\n",
      "[ Switch Colors ]\n",
      "\n",
      "MDMA (pill / tablet)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "BODY WEIGHT:\n",
      "125 able and the night in a past time in my body some in a person at the ward in a going to seen out and in a some most a fut me to me the the pill as a body in about\n",
      "\n",
      "\n",
      "\n",
      "I was a this my gime me to go to a suppost the car to puspeepus a mass his danned me all about\n",
      "\n",
      "\n",
      "\n",
      "I stare to me, a plange on and I dont the park so I could started to go to pla\n"
     ]
    }
   ],
   "source": [
    "mdma, mdma_x, mdma_y = make_model(mdma_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate trained model, to check saved and retreived model later\n",
    "def eval_model(model, x, y):\n",
    "    print(model.evaluate(x[-2000:], y[-2000:], verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trained_model(trained_model, drug_name):\n",
    "    now = datetime.now()\n",
    "    model_json = trained_model.to_json()\n",
    "    filename = drug_name + \"_\" + now.strftime(\"%m-%d_%H-%M-%S\")\n",
    "    with open(\"saved_models/\" + filename + \".json\", \"w+\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights\n",
    "    trained_model.save_weights(\"saved_models/\" + filename + \".h5\")\n",
    "    print(drug_name + \"_\" + now.strftime(\"%m-%d_%H-%M-%S\") + \" model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(filename):\n",
    "    # load model\n",
    "    json_file = open(\"saved_models/\" + filename + \".json\", \"r\")\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = keras.models.model_from_json(loaded_model_json)\n",
    "    # load weights\n",
    "    loaded_model.load_weights(\"saved_models/\" + filename + \".h5\")\n",
    "    print(filename + \" model loaded\")\n",
    "    # compile\n",
    "    loaded_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=RMSprop(learning_rate=0.1),\n",
    "        metrics=['categorical_crossentropy', 'accuracy']\n",
    "    )\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.505263566017151, 1.5052634477615356, 0.557812511920929]\n",
      "mushrooms_11-30_16-56-31 model saved!\n"
     ]
    }
   ],
   "source": [
    "eval_model(mushrooms, mush_x, mush_y)\n",
    "save_trained_model(mushrooms, \"mushrooms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mushrooms_11-30_16-56-31 model loaded\n",
      "[1.505263566017151, 1.5052634477615356, 0.557812511920929]\n"
     ]
    }
   ],
   "source": [
    "# hardcode filename here\n",
    "model_loaded = load_trained_model(\"mushrooms_11-30_16-56-31\")\n",
    "eval_model(model_loaded, mush_x, mush_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
